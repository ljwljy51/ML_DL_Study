{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Fold\n",
    "\n",
    "제가 데이터를 다운로드 하여 놓은 경로는 \"/workspace/Dacon/\" 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/workspace/Dacon/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['cat3'].values)\n",
    "df['cat3'] = le.transform(df['cat3'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5일장', 'ATV', 'MTB', '강', '게스트하우스', '계곡', '고궁', '고택', '골프', '공연장',\n",
       "       '공예,공방', '공원', '관광단지', '국립공원', '군립공원', '기념관', '기념탑/기념비/전망대',\n",
       "       '기암괴석', '기타', '기타행사', '농.산.어촌 체험', '다리/대교', '대중콘서트', '대형서점',\n",
       "       '도립공원', '도서관', '동굴', '동상', '등대', '래프팅', '면세점', '모텔', '문', '문화관광축제',\n",
       "       '문화원', '문화전수시설', '뮤지컬', '미술관/화랑', '민물낚시', '민박', '민속마을', '바/까페',\n",
       "       '바다낚시', '박람회', '박물관', '발전소', '백화점', '번지점프', '복합 레포츠', '분수', '빙벽등반',\n",
       "       '사격장', '사찰', '산', '상설시장', '생가', '서비스드레지던스', '서양식', '섬', '성',\n",
       "       '수련시설', '수목원', '수상레포츠', '수영', '스노쿨링/스킨스쿠버다이빙', '스카이다이빙', '스케이트',\n",
       "       '스키(보드) 렌탈샵', '스키/스노보드', '승마', '식음료', '썰매장', '안보관광', '야영장,오토캠핑장',\n",
       "       '약수터', '연극', '영화관', '온천/욕장/스파', '외국문화원', '요트', '윈드서핑/제트스키',\n",
       "       '유람선/잠수함관광', '유명건물', '유스호스텔', '유원지', '유적지/사적지', '이색거리', '이색찜질방',\n",
       "       '이색체험', '인라인(실내 인라인 포함)', '일반축제', '일식', '자동차경주', '자연생태관광지',\n",
       "       '자연휴양림', '자전거하이킹', '전문상가', '전시관', '전통공연', '종교성지', '중식', '채식전문점',\n",
       "       '카약/카누', '카지노', '카트', '컨벤션', '컨벤션센터', '콘도미니엄', '클래식음악회', '클럽',\n",
       "       '터널', '테마공원', '트래킹', '특산물판매점', '패밀리레스토랑', '펜션', '폭포', '학교', '한식',\n",
       "       '한옥스테이', '항구/포구', '해수욕장', '해안절경', '헬스투어', '헹글라이딩/패러글라이딩', '호수',\n",
       "       '홈스테이', '희귀동.식물'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['cat2'].values)\n",
    "df['cat2'] = le.transform(df['cat2'].values)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['cat1'].values)\n",
    "df['cat1'] = le.transform(df['cat1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "df['kfold'] = -1\n",
    "for i in range(5):\n",
    "    df_idx, valid_idx = list(folds.split(df.values, df['cat3']))[i]\n",
    "    valid = df.iloc[valid_idx]\n",
    "\n",
    "    df.loc[df[df.id.isin(valid.id) == True].index.to_list(), 'kfold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/workspace/Dacon/data/train_folds.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>overview</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>./image/train/TRAIN_00000.jpg</td>\n",
       "      <td>소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>./image/train/TRAIN_00001.jpg</td>\n",
       "      <td>경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>./image/train/TRAIN_00002.jpg</td>\n",
       "      <td>금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>./image/train/TRAIN_00003.jpg</td>\n",
       "      <td>철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>./image/train/TRAIN_00004.jpg</td>\n",
       "      <td>※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16981</th>\n",
       "      <td>TRAIN_16981</td>\n",
       "      <td>./image/train/TRAIN_16981.jpg</td>\n",
       "      <td>해발 12000m에 자리한 식담겸 카페점문점이다.&lt;br&gt;곤드레밥과 감자전을 판매하고...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982</th>\n",
       "      <td>TRAIN_16982</td>\n",
       "      <td>./image/train/TRAIN_16982.jpg</td>\n",
       "      <td>설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16983</th>\n",
       "      <td>TRAIN_16983</td>\n",
       "      <td>./image/train/TRAIN_16983.jpg</td>\n",
       "      <td>충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16984</th>\n",
       "      <td>TRAIN_16984</td>\n",
       "      <td>./image/train/TRAIN_16984.jpg</td>\n",
       "      <td>토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>TRAIN_16985</td>\n",
       "      <td>./image/train/TRAIN_16985.jpg</td>\n",
       "      <td>포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16986 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                       img_path  \\\n",
       "0      TRAIN_00000  ./image/train/TRAIN_00000.jpg   \n",
       "1      TRAIN_00001  ./image/train/TRAIN_00001.jpg   \n",
       "2      TRAIN_00002  ./image/train/TRAIN_00002.jpg   \n",
       "3      TRAIN_00003  ./image/train/TRAIN_00003.jpg   \n",
       "4      TRAIN_00004  ./image/train/TRAIN_00004.jpg   \n",
       "...            ...                            ...   \n",
       "16981  TRAIN_16981  ./image/train/TRAIN_16981.jpg   \n",
       "16982  TRAIN_16982  ./image/train/TRAIN_16982.jpg   \n",
       "16983  TRAIN_16983  ./image/train/TRAIN_16983.jpg   \n",
       "16984  TRAIN_16984  ./image/train/TRAIN_16984.jpg   \n",
       "16985  TRAIN_16985  ./image/train/TRAIN_16985.jpg   \n",
       "\n",
       "                                                overview  cat1  cat2  cat3  \\\n",
       "0      소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...     5    13   120   \n",
       "1      경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...     0    11     8   \n",
       "2      금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...     3    12   118   \n",
       "3      철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...     3    12   118   \n",
       "4      ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...     3    12   118   \n",
       "...                                                  ...   ...   ...   ...   \n",
       "16981  해발 12000m에 자리한 식담겸 카페점문점이다.<br>곤드레밥과 감자전을 판매하고...     3    12   118   \n",
       "16982  설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...     2     9    31   \n",
       "16983  충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...     2     9    31   \n",
       "16984  토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...     0    11    73   \n",
       "16985  포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...     4    10    52   \n",
       "\n",
       "       kfold  \n",
       "0          4  \n",
       "1          4  \n",
       "2          4  \n",
       "3          3  \n",
       "4          1  \n",
       "...      ...  \n",
       "16981      0  \n",
       "16982      1  \n",
       "16983      4  \n",
       "16984      1  \n",
       "16985      3  \n",
       "\n",
       "[16986 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "df = pd.read_csv('/workspace/Dacon/data/train_folds.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CategoryDataset(Dataset):\n",
    "  def __init__(self, text, image_path, cats1, cats2, cats3, tokenizer, feature_extractor, max_len):\n",
    "    self.text = text\n",
    "    self.image_path = image_path\n",
    "    self.cats1 = cats1\n",
    "    self.cats2 = cats2\n",
    "    self.cats3 = cats3\n",
    "    self.tokenizer = tokenizer\n",
    "    self.feature_extractor = feature_extractor\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.text[item])\n",
    "    image_path = os.path.join('/workspace/Dacon/data',str(self.image_path[item])[2:])\n",
    "    image = cv2.imread(image_path)\n",
    "    cat = self.cats1[item]\n",
    "    cat2 = self.cats2[item]\n",
    "    cat3 = self.cats3[item]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    image_feature = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    return {\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'pixel_values': image_feature['pixel_values'][0],\n",
    "      'cats1': torch.tensor(cat, dtype=torch.long),\n",
    "      'cats2': torch.tensor(cat2, dtype=torch.long),\n",
    "      'cats3': torch.tensor(cat3, dtype=torch.long)\n",
    "    }\n",
    "\n",
    "def create_data_loader(df, tokenizer, feature_extractor, max_len, batch_size, shuffle_=False):\n",
    "    ds = CategoryDataset(\n",
    "        text=df.overview.to_numpy(),\n",
    "        image_path = df.img_path.to_numpy(),\n",
    "        cats1=df.cat1.to_numpy(),\n",
    "        cats2=df.cat2.to_numpy(),\n",
    "        cats3=df.cat3.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        feature_extractor = feature_extractor,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        shuffle = shuffle_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel,ViTModel,ViTFeatureExtractor\n",
    "import torch.nn as nn\n",
    "\n",
    "class TourClassifier(nn.Module):\n",
    "  def __init__(self, n_classes1, n_classes2, n_classes3, text_model_name, image_model_name):\n",
    "    super(TourClassifier, self).__init__()\n",
    "    self.text_model = AutoModel.from_pretrained(text_model_name).to(device)\n",
    "    self.image_model = ViTModel.from_pretrained(image_model_name).to(device)\n",
    "    \n",
    "    self.text_model.gradient_checkpointing_enable()  \n",
    "    self.image_model.gradient_checkpointing_enable()  \n",
    "\n",
    "    self.drop = nn.Dropout(p=0.1)\n",
    "\n",
    "    def get_cls(target_size):\n",
    "      return nn.Sequential(\n",
    "          nn.Linear(self.text_model.config.hidden_size, self.text_model.config.hidden_size),\n",
    "          nn.LayerNorm(self.text_model.config.hidden_size),\n",
    "          nn.Dropout(p = 0.1),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(self.text_model.config.hidden_size, target_size),\n",
    "      )  \n",
    "    self.cls = get_cls(n_classes1)\n",
    "    self.cls2 = get_cls(n_classes2)\n",
    "    self.cls3 = get_cls(n_classes3)\n",
    "    \n",
    "  def forward(self, input_ids, attention_mask,pixel_values):\n",
    "    text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    image_output = self.image_model(pixel_values = pixel_values)\n",
    "    concat_outputs = torch.cat([text_output.last_hidden_state, image_output.last_hidden_state],1)\n",
    "    #config hidden size 일치해야함\n",
    "    encoder_layer = nn.TransformerEncoderLayer(d_model=self.text_model.config.hidden_size, nhead=8).to(device)\n",
    "    transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2).to(device)\n",
    "\n",
    "    outputs = transformer_encoder(concat_outputs)\n",
    "    #cls token \n",
    "    outputs = outputs[:,0]\n",
    "    output = self.drop(outputs)\n",
    "\n",
    "    out1 = self.cls(output)\n",
    "    out2 = self.cls2(output)\n",
    "    out3 = self.cls3(output)\n",
    "    return out1,out2,out3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "def calc_tour_acc(pred, label):\n",
    "    _, idx = pred.max(1)\n",
    "    \n",
    "    acc = torch.eq(idx, label).sum().item() / idx.size()[0] \n",
    "    x = label.cpu().numpy()\n",
    "    y = idx.cpu().numpy()\n",
    "    f1_acc = f1_score(x, y, average='weighted')\n",
    "    return acc,f1_acc\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import argparse\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.optim as optim\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples,epoch):\n",
    "\n",
    "  batch_time = AverageMeter()     \n",
    "  data_time = AverageMeter()      \n",
    "  losses = AverageMeter()         \n",
    "  accuracies = AverageMeter()\n",
    "  f1_accuracies = AverageMeter()\n",
    "  \n",
    "  sent_count = AverageMeter()   \n",
    "    \n",
    "\n",
    "  start = end = time.time()\n",
    "\n",
    "  model = model.train()\n",
    "  correct_predictions = 0\n",
    "  for step,d in enumerate(data_loader):\n",
    "    data_time.update(time.time() - end)\n",
    "    batch_size = d[\"input_ids\"].size(0) \n",
    "\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    pixel_values = d['pixel_values'].to(device)\n",
    "    cats1 = d[\"cats1\"].to(device)\n",
    "    cats2 = d[\"cats2\"].to(device)\n",
    "    cats3 = d[\"cats3\"].to(device)\n",
    "\n",
    "    outputs,outputs2,outputs3 = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      pixel_values=pixel_values\n",
    "    )\n",
    "    _, preds = torch.max(outputs3, dim=1)\n",
    "\n",
    "    loss1 = loss_fn(outputs, cats1)\n",
    "    loss2 = loss_fn(outputs2, cats2)\n",
    "    loss3 = loss_fn(outputs3, cats3)\n",
    "\n",
    "    loss = loss1 * 0.05 + loss2 * 0.1 + loss3 * 0.85\n",
    "\n",
    "    correct_predictions += torch.sum(preds == cats3)\n",
    "    losses.update(loss.item(), batch_size)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "\n",
    "    sent_count.update(batch_size)\n",
    "    if step % 200 == 0 or step == (len(data_loader)-1):\n",
    "                acc,f1_acc = calc_tour_acc(outputs3, cats3)\n",
    "                accuracies.update(acc, batch_size)\n",
    "                f1_accuracies.update(f1_acc, batch_size)\n",
    "\n",
    "                \n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.3f}({loss.avg:.3f}) '\n",
    "                      'Acc: {acc.val:.3f}({acc.avg:.3f}) '   \n",
    "                      'f1_Acc: {f1_acc.val:.3f}({f1_acc.avg:.3f}) '           \n",
    "                      'sent/s {sent_s:.0f} '\n",
    "                      .format(\n",
    "                      epoch, step+1, len(data_loader),\n",
    "                      data_time=data_time, loss=losses,\n",
    "                      acc=accuracies,\n",
    "                      f1_acc=f1_accuracies,\n",
    "                      remain=timeSince(start, float(step+1)/len(data_loader)),\n",
    "                      sent_s=sent_count.avg/batch_time.avg\n",
    "                      ))\n",
    "\n",
    "  return correct_predictions.double() / n_examples, losses.avg\n",
    "\n",
    "def validate(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  cnt = 0\n",
    "  for d in tqdm(data_loader):\n",
    "    with torch.no_grad():\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      pixel_values = d['pixel_values'].to(device)\n",
    "      cats1 = d[\"cats1\"].to(device)\n",
    "      cats2 = d[\"cats2\"].to(device)\n",
    "      cats3 = d[\"cats3\"].to(device)\n",
    "      outputs,outputs2,outputs3 = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        pixel_values=pixel_values\n",
    "      )\n",
    "      _, preds = torch.max(outputs3, dim=1)\n",
    "      loss1 = loss_fn(outputs, cats1)\n",
    "      loss2 = loss_fn(outputs2, cats2)\n",
    "      loss3 = loss_fn(outputs3, cats3)\n",
    "\n",
    "      loss = loss1 * 0.05 + loss2 * 0.1 + loss3 * 0.85\n",
    "\n",
    "      correct_predictions += torch.sum(preds == cats3)\n",
    "      losses.append(loss.item())\n",
    "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "      if cnt == 0:\n",
    "        cnt +=1\n",
    "        outputs3_arr = outputs3\n",
    "        cats3_arr = cats3\n",
    "      else:\n",
    "        outputs3_arr = torch.cat([outputs3_arr, outputs3],0)\n",
    "        cats3_arr = torch.cat([cats3_arr, cats3],0)\n",
    "  acc,f1_acc = calc_tour_acc(outputs3_arr, cats3_arr)\n",
    "  return f1_acc, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at google/vit-large-patch32-384 were not used when initializing ViTModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-large-patch32-384 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train = df[df[\"kfold\"] != 0].reset_index(drop=True)\n",
    "valid = df[df[\"kfold\"] == 0].reset_index(drop=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch32-384')\n",
    "train_data_loader = create_data_loader(train, tokenizer, feature_extractor, 256, 16, shuffle_=True)\n",
    "valid_data_loader = create_data_loader(valid, tokenizer, feature_extractor, 256, 16)\n",
    "\n",
    "\n",
    "EPOCHS = 30\n",
    "model = TourClassifier(n_classes1 = 6, n_classes2 = 18, n_classes3 = 128, text_model_name = \"klue/roberta-large\",image_model_name = \"google/vit-large-patch32-384\").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr= 3e-5)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "optimizer,\n",
    "num_warmup_steps=int(total_steps*0.1),\n",
    "num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print('-' * 10)\n",
    "    print(f'Epoch {epoch}/{EPOCHS-1}')\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train),\n",
    "        epoch\n",
    "    )\n",
    "    validate_acc, validate_loss = validate(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(valid)\n",
    "    )\n",
    "\n",
    "    if validate_acc > max_acc:\n",
    "        max_acc = validate_acc\n",
    "        torch.save(model.state_dict(),f'tourbaseline_fold0.pt')\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    print(f'Validate loss {validate_loss} accuracy {validate_acc}')\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryDataset(Dataset):\n",
    "  def __init__(self, text, image_path, tokenizer, feature_extractor, max_len):\n",
    "    self.text = text\n",
    "    self.image_path = image_path\n",
    "    self.tokenizer = tokenizer\n",
    "    self.feature_extractor = feature_extractor\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "  def __getitem__(self, item):\n",
    "    text = str(self.text[item])\n",
    "    image_path = os.path.join('/workspace/Dacon/data',str(self.image_path[item])[2:])\n",
    "    image = cv2.imread(image_path)\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    image_feature = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    return {\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'pixel_values': image_feature['pixel_values'][0],\n",
    "    }\n",
    "\n",
    "def create_data_loader(df, tokenizer, feature_extractor, max_len, batch_size, shuffle_=False):\n",
    "    ds = CategoryDataset(\n",
    "        text=df.overview.to_numpy(),\n",
    "        image_path = df.img_path.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        feature_extractor = feature_extractor,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        shuffle = shuffle_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model,data_loader,device,n_examples):\n",
    "  model = model.eval()\n",
    "  preds_arr = []\n",
    "  preds_arr2 = []\n",
    "  preds_arr3 = []\n",
    "  for d in tqdm(data_loader):\n",
    "    with torch.no_grad():\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      pixel_values = d['pixel_values'].to(device)\n",
    "\n",
    "      outputs,outputs2,outputs3 = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        pixel_values=pixel_values\n",
    "      )\n",
    "\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      _, preds2 = torch.max(outputs2, dim=1)\n",
    "      _, preds3 = torch.max(outputs3, dim=1)\n",
    "\n",
    "      preds_arr.append(preds.cpu().numpy())\n",
    "      preds_arr2.append(preds2.cpu().numpy())\n",
    "      preds_arr3.append(preds3.cpu().numpy())\n",
    "\n",
    "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "  return preds_arr, preds_arr2, preds_arr3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/workspace/Dacon/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7280/7280 [12:04<00:00, 10.05it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_data_loader = create_data_loader(test, tokenizer, feature_extractor, 256, 1)\n",
    "\n",
    "preds_arr, preds_arr2, preds_arr3 = inference(\n",
    "        model,\n",
    "        eval_data_loader,\n",
    "        device,\n",
    "        len(test)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('/workspace/Dacon/data/sample_submission.csv')\n",
    "arr = ['5일장', 'ATV', 'MTB', '강', '게스트하우스', '계곡', '고궁', '고택', '골프', '공연장',\n",
    "       '공예,공방', '공원', '관광단지', '국립공원', '군립공원', '기념관', '기념탑/기념비/전망대',\n",
    "       '기암괴석', '기타', '기타행사', '농.산.어촌 체험', '다리/대교', '대중콘서트', '대형서점',\n",
    "       '도립공원', '도서관', '동굴', '동상', '등대', '래프팅', '면세점', '모텔', '문', '문화관광축제',\n",
    "       '문화원', '문화전수시설', '뮤지컬', '미술관/화랑', '민물낚시', '민박', '민속마을', '바/까페',\n",
    "       '바다낚시', '박람회', '박물관', '발전소', '백화점', '번지점프', '복합 레포츠', '분수', '빙벽등반',\n",
    "       '사격장', '사찰', '산', '상설시장', '생가', '서비스드레지던스', '서양식', '섬', '성',\n",
    "       '수련시설', '수목원', '수상레포츠', '수영', '스노쿨링/스킨스쿠버다이빙', '스카이다이빙', '스케이트',\n",
    "       '스키(보드) 렌탈샵', '스키/스노보드', '승마', '식음료', '썰매장', '안보관광', '야영장,오토캠핑장',\n",
    "       '약수터', '연극', '영화관', '온천/욕장/스파', '외국문화원', '요트', '윈드서핑/제트스키',\n",
    "       '유람선/잠수함관광', '유명건물', '유스호스텔', '유원지', '유적지/사적지', '이색거리', '이색찜질방',\n",
    "       '이색체험', '인라인(실내 인라인 포함)', '일반축제', '일식', '자동차경주', '자연생태관광지',\n",
    "       '자연휴양림', '자전거하이킹', '전문상가', '전시관', '전통공연', '종교성지', '중식', '채식전문점',\n",
    "       '카약/카누', '카지노', '카트', '컨벤션', '컨벤션센터', '콘도미니엄', '클래식음악회', '클럽',\n",
    "       '터널', '테마공원', '트래킹', '특산물판매점', '패밀리레스토랑', '펜션', '폭포', '학교', '한식',\n",
    "       '한옥스테이', '항구/포구', '해수욕장', '해안절경', '헬스투어', '헹글라이딩/패러글라이딩', '호수',\n",
    "       '홈스테이', '희귀동.식물']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preds_arr3)):\n",
    "    sample_submission.loc[i,'cat3'] = arr[preds_arr3[i][0]]\n",
    "\n",
    "sample_submission.to_csv('baseline.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
